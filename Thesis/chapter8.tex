\chapter{Cloth Resizing}
\label{chapter8}
My cloth resizing algorithm consists of three main steps:
\begin{enumerate}
\item Improve the raw depth map from Kinect by filtering.
\item Fit the contour on the user blob and perform measurements. Compare with known human body proportions to acquire required scaling parameters.
\item Perform the same measurements over a time frame in order to smooth the results. Scale the virtual avatar along with the cloth mesh prior to simulation.
\end{enumerate}

\section{Depth Map Optimization}
\label{section_8_1}

At 30 fps, Kinect provides a depth map and a user map, both at 640x480 resolution. Depth map consists of distances with the sensor in millimeters. 

The depth measurement of the Kinect is not very accurate compared to high end 3D
depth systems like laser scanners. The accuracy of the depth value decreases
quadratically. Error values for different distances is shown in Table
\ref{tbl:error_kinect}.

\begin{table}
\center
\begin{tabular}{ | l | l | l | l |}
\hline
\textbf{Distance of Point} & 1m & 3m & 5m \\ \hline
\textbf{Error in measurement} & 0.5cm & 1.5cm & 4cm \\ 
\hline
\end{tabular}
\caption{Kinect Depth Accuracy \cite{Kourosh2012}}
\label{tbl:error_kinect}
\end{table}

For my application, the Kinect needs to be able to see the whole human body,
which requires at least 3m away from the sensor for a person with 1.7m height,
resulting in an erroneous depth map. This problem can be seen in Figure
\ref{fig:kinect_depth_output_comparison}.


\begin{figure}[h]
\centerline{\fbox{\psfig{figure=figures/kinect_depth_output_comparison.png,width=1.00\textwidth}}}
\caption{Depth Output From Kinect with Improved Results. The leftmost image is
the raw output, the application of filters results in better performance in the other two images  \cite{Tong2012}. This improvement utilizes more than one depth streams. }
\label{fig:kinect_depth_output_comparison}
\end{figure}

In order to acquire a better depth map, I will perform the following operations:

Let us take the depth map D as a 640x480 matrix. Initially, the user pixels are
extracted by a pixel-by-pixel comparison with the user map. User map is another
acquired map from the sensor, with the same size as depth map. The value of a
pixel is set to a non-zero value if the pixel belongs to a recognized user. In
this case, we are only interested in one user, $D_1$ represents the depth pixels
of the user we are interested in, whereas $U_1$ is the bit map of the user.
Also, the non-user pixels must be filled with the mean value of the user pixels, in order to perform Gaussian filtering on the image.

Next, we perform Gaussian filtering on the userâ€™s depth map, to normalize and
improve the quality of the depth map. The size and sigma parameters of the Gaussian filter will be varied in order to maximize the performance and the quality of the results. 

After these operations, we have a normalized and filtered depth map, which also
has better planar values (x and y) since the holes due to depth stream will be filled.







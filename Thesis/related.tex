\chapter{Related Work}
\label{chapter_related_work}

Virtual fitting frameworks are complex systems composed of many modules. The related works on the major components of our framework are summarized in this chapter, 
along with the history of the general framework. 

The overall framework can be divided into four major modules: \textit{human body modeling and animation}, \textit{motion capture systems} and 
\textit{cloth modeling and simulation}. Although these topics are connected in many ways, their foundations are distinct 
and should be discussed separately, followed by the discussion of the work on virtual fitting rooms.

\section{Human Body Modeling And Animation}
\label{section_related_modeling}

Although the human and apparel modeling both have foundations in 3D mesh creation, they require different traits and qualities. Human body modeling utilizes disciplines such as rigging and skinning, whereas apparel modeling is mostly based on physics simulations.

\subsection{Human Body Modeling}
As we humans are mostly the main characters in virtual worlds, very different methods and techniques exist for human body models and animations. Determining the suitable one 
starts with the requirements of the application. Real-time applications require a certain level of simplicity, as the simulation time cannot exceed the frame duration. Offline 
applications can utilize very higher detail models, looking much more realistic. The basis for both extremes however, is the same, which is a skeleton. The approach is starting 
with a connected set of rigid objects named as \textit{bones}, continuing by adding layers of muscle, skin, hair and others, depending on the required quality level. Called \textit{layered
modeling technique}, this is a very common modeling technique used in computer graphics \cite{Chadwick1989}. The animation is achieved by rotating the bones, which is followed by 
upper layers. This technique also improves the reusability of the framework, as the same animation sequence can be used for multiple body models with different detail levels utilizing the 
same base skeleton.   

The articulated skeleton consists of a hierarchical structure of joints and limbs to model a human-like skeleton. Joints are the points which act as the origin of the respective 
local coordinate space. The limbs are the rigid segments which connect the joints in the hierarchy. Rotation in the local coordinate systems defined by the joints cause the rigid
limbs to be rotated, resulting in the motion. The complexity of the model can be determined by the number of joints and the degrees of freedoms - abbreviated as \textit{DOF}s.
Degree of freedom is defined as ``the number of independent parameters that define its configuration''\cite{Lazard2013}. A joint can rotate and translate in at most three orthogonal
directions, hence the maximum DOF a joint can have is six. Although having the maximum number of DOFs in a human body model might seem like a good way to improve the realism, 
however this also increases the complexity of the structure, resulting in more mathematical operations. As most human-body joints can only rotate, not translate, assigning six 
degrees of freedom to every joint is redundant. Furthermore, angular and axis constraints with certain joints (such as knee or elbow) further simplify the model while making it 
more realistic. 

In order to provide a common basis and a standard for modeling of 3D humans with hierarchical skeletons, Humanoid Animation (H-Anim) specification was developed by 
Web3D Consortium\cite{HANIM}. Different levels of articulation are provided in X3D/VRML format, focusing specifically on humanoid objects rather than random 
articulated figures. H-Anim standard provides a common ground for applications to be classified depending on their humanoid animation complexity, mainly by the 
number of joints and DOFs. 

\subsection{Human Body Animation}
\label{section_related_human_body_animation}

Animating humanoid meshes is a complex and old subject of computer science, as there are many factors which contribute to the way humans move. The task gets 
even harder with the ability of the human eye to distinguish very minor unnatural movements. The long history of humanoid animation starts with stick figures 
and evolves to multi-layered high resolution meshes. 

Stick figured animation dates back to 1970s, where the technology would limit the qualities of animation to one dimensional limbs\cite{Badler1979}.
With the advances in computer hardware, the details have improved and the complexities are increased. Surface models were the first improvement on top 
of the original stick figure animation. A surface or ``skin'', which envelopes the articulated skeleton is 
introduced to the model. The translation of the surface varies depending on how the vertices are assigned to the bones. The process of assigning vertices to 
a specific joint or set of joints is called skinning. The quality of the animation depends on both the complexity of the skeleton as well as the skinning 
quality and technique. 

The initial approach to the animation of enveloped surface was assigning weights to the individual polygons. However, this approach resulted in broken surfaces
almost every frame. The first solution to this problem was introduced by Komatsu \cite{Komatsu1988}, where a continuous deformation function is used with respect 
to the joints. 

The next step in skinning was assigning vertices to joints instead of polygons\cite{Lander1988}. This simple difference allowed a polygon to be assigned to multiple bones, 
preventing two polygons from separating as the common vertices would not get ripped.

Although assigning vertices instead of polygons to bones improved the realism significantly, it produced artifacts in extreme rotations. Inspired by the true 
nature of human skin and deformation, the new solution introduced assigning a vertex to multiple joints. Called linear blend skinning, this technique further 
improved the quality of character animations. However, it still was not sufficient with certain parts of body such as forearm and elbow, where the bone 
positioning and configuration are more complex than a single series of connected bones. An example of this situation can be seen in Figure \ref{fig:forearm-comparison}.
A single bone cannot imitate the twisting motion enabled by two parallel bones. Various solutions to this problem has been proposed, ours is described in 
Section \ref{subsection_bone_splitting}. 

A new deformation technique called Double Quaternion Skinning overcomes these artifacts without introducing additional time complexity\cite{Kavan2007}, even 
improving the performance. Quaternions, which are primarily used as a notation for rotations can also be used to define translations. Dual Quaternions can 
be blended for rigid transformations and produce much more realistic results.

Another approach to fixing the extreme rotation situations was proposed by Kavan et al.\cite{Kavan2009}, where the bones which could not produce realistic 
results would be split into child bones in runtime. This approach, although successfully correcting the otherwise present artifacts, required significantly more
computational power and was not suitable for real-time applications. 


\section{Motion Capture Systems}
\label{section_related_mocap}
 Since the human body is a complex articulated system, creating artificial motions from scratch is found to be tedious, labor intensive and not very successful.
 The solution to providing animation data to virtual models is recording the motions of real humans and applying the same transformations. First bricks laid by
 Calvert et al. \cite{Calvert1982}, motion capture systems today utilize a variety of techniques to capture the human and other motions for different purposes.
 
 There are two base disciplines for motion capture systems- optical and non-optical.
 
\subsection{Non-Optical Motion Capture Systems}
 
 Non-optical systems are based on mechanics, inertia\cite{Miller2004} and magnetics\cite{Yabukami2000}. Mechanical systems were the earliest examples of motion capture systems and 
 their cumbersome hardware requirements make them hard to use. Inertial systems utilize inertia sensors to determine the global orientation of the body part they 
 are attached to, which can later be converted to local orientations in post processing. Magnetic systems perform the same operation, except they do so by measuring 
 the magnetic field emitted by the magnetic markers. Non-optical systems tend to deliver more accurate results than optical motion capture systems, although 
 their hardware requirements and harness to use are two major drawbacks. 
 
\subsection{Optical Motion Capture Systems}

 Optical systems are based on recording the target in action by one or more 
 cameras. The most common approaches in optical motion capture systems utilize some sort of markers placed on key positions of the target. Markers can be passive
 \cite{Sementille2004} or active\cite{Maletsky2007}, depending on whether they just reflect the light or they emit light themselves. Regardless, their task is 
 identical in both cases, providing the camera with the positional information of key parts of the body. 
 
 With the advances in computer processing power and camera technology, markerless motion capture systems have emerged\cite{Cheung2003}. Theobalt, Aguiar and their team in Max 
 Planck Institute have played an important role in the markerless human motion capture systems from multi view video sequences \cite{Aguiar2007,Gall2009,Liu2011}. Their framework
 utilizes 8 or more cameras placed on a circle around the target. They construct a volumetric visual hull by getting the intersection of extruded 2D silhouettes 
 - which is called shape from silhouette technique\cite{Cheung2000,Cheung2005}. Using a set of cameras rather than a single camera is a remedy to the self-occlusion
 problem. After the visual hull of the user is acquired, the hull is segmented into body parts by fitting a pre-defined body model. Accurate as they are, these
 applications require immense computing power and are not suitable for real time applications. 
 
 The emergence of the consumer-level depth sensors at affordable costs opened a new page for markerless motion capturing\cite{Dutta2012}. As the depth sensors operate in real time
 and the visual hull is the input rather than a processing product, the computation time for skeletal position estimation is considerably lower, enabling 
 real-time motion transferring from actors to virtual avatars. However, depth sensors suffer from the same disadvantage as single-camera systems- self occlusion,
 although this problem can be solved partially by utilizing multiple depth sensors\cite{Berger2011}.
 Furthermore, the IR and TOF depth sensing technology are not evolved enough yet to provide high resolution depth frames and produce quite a bit of noise, hence 
 reducing the output motion quality. Various filters for improving the results have been developed and applied\cite{Matyunin2011,Camplani2012}. 
 
 \section{Cloth Modeling and Simulation}
 
 A number of industries, entertainment and apparel commerce coming first, created a demand for rapid virtual apparel design and realistic simulation along 
 with the advances in computer graphics. Like every other physical phenomenon though, garment simulation is no simple task to solve in virtual worlds. To be able
 to create realistic render results for entertainment industry while keeping the physical properties accurate requires very complex simulation frameworks and 
 physics engines. 
 
 \subsection{Cloth Design and Modeling}
 
 Garment design aims at creating meshes which look realistic. Garments designed for virtual simulation environments must also be suitable for physics simulation. 
 The two approaches to creating 3D garment meshes are straightforward 3D design and combining 2D designed patches by ``stitching''. However, the greater separation
 between garment design suites and techniques depend on the desired outcome, whether it is a production sample or a virtual model for simulation.
 
\subsubsection{Production Oriented Design Systems}

  The design suites explained in this section focus on product creation and industrial usage of the apparel design, rather than virtual simulation. 
  As the goals of two systems are different, other design techniques are used for simulation purposes. However, the underlying 2D and 3D design principles 
  are quite similar.
  
  First approaches of 2D garment design consisted of two parts where each have several steps\cite{Yang2007}:  
 
 \begin{enumerate}
\item Parametric Design Based Pattern Generation
\item Pattern Alteration Based on Grading Techniques
\end{enumerate}    
 
 A widely used CAD suite with this approach is Gerbert Technologies' AccuMark solution\cite{Gerbert2013}. 
 
 A major drawback of 2D garment design systems is the necessity of a certain level of expertise with pattern design, as the 2D patches are not easy to visualize 
 for an inexperienced person. 3D garment design is the solution to this problem as the apparel can be modeled on virtual human models directly and then separated 
 into multiple parts for production. In order to create realistic apparels, the underlying 3D human model must be realistic itself; best way is to obtain the mesh 
 from a 3D full body scan. Assyst-Bullmer's design software is an example of such CAD suites\cite{Assyst2013}. 
 
\subsubsection{Simulation Oriented Design Systems} 
 
 Simulation oriented design systems aim at creating garment meshes which are suitable for using in virtual environments, mainly in entertainment software such 
 as video games, and recently, in virtual fitting rooms. The output of these suites must not be too complex to be simulated in real time, yet be realistic enough
 to give the user the feeling of the fitting experience.
 
 One of the first physics-enabled 2D garment design systems was introduced by Yang et al.\cite{Yang1992}. The suite included 2D design panels, deformable cloth modeling and
 a human body model which could be used to simulate the designed apparel on. Chittaro and Corvaglio\cite{Chittaro2003} aimed to develop a platform which would connect
 the textile industry with computer graphics and simulation world via defining an interchangeable format with VRML-based 3D meshes from 2D patterns. 
 Turquin et al. developed a sketch based interface for tailoring, dressing and simulating clothing pieces on virtual characters\cite{Turquin2007}.
 
 3D CAD systems suit simulation oriented design better than 2D by the nature of the general applications. The system developed by Bonte et al.\cite{Bonte2002} reverses the process
 defined in the previous examples, where the garment is designed in 3D and 2D patterns are generated from it. Garments are modeled on a mannequin to conform with the body characteristics
 of humans. The framework also includes a particle-based simulation feature. Cugini and Rizzi developed a framework\cite{Cugini2002} for the design of men apparel items with a 2D/3D 
 hybrid approach using Autodesk Maya\cite{Autodesk2013} for 3D modeling and simulation. A similar system was proposed by Durup{\i}nar and G{\"u}d{\"u}kbay\cite{Durupinar2007} where the 3D garments
 would be created from 2D patterns and simulated using a mass-spring system.
 
 The GPU company NVIDIA's PhysX physics engine is one the best options for real-time physics simulation available\cite{WikiPhysx2012}. An extension of this engine, APEX is a scalable 
 dynamics framework with specialized physic based utilities such as destruction, particles, turbulence(fluids) and clothing\cite{Nvidia2013}. The modeling extension of this framework
 is available as an extension for 3dsMax\cite{Autodesk3DS2013} and Maya\cite{Autodesk2013} design suites. The extensions provide an interface which are aimed at creating an artist-oriented environment as 
 possible, abstracting all the programming work. As the PhysX engine is optimized for NVIDIA GPUs, the easiness of the APEX along with its performance make it one of the 
 best options for real-time clothing design-and-simulation framework.  
 
 With the advances in virtual try on systems, various frameworks for apparel design solely for the use with such environments emerged. The state of these frameworks will be discussed 
 in Section \ref{section_related_virtual_fitting} along with virtual fitting room frameworks.  
   
\subsection{Garment Simulation}
Garment simulation is mainly deforming an apparel mesh in a way which feels natural to the eye. It also includes collision detection and support for tearing behaviour. The nature of the garment simulation depends on the used modeling approach. 
Two common garment modeling approaches are geometrical models\cite{Weil1986} and physics-based models. 

\subsubsection{Geometric Garment Modeling}
Geometric models 
do not take the physical properties such as stiffness and stretching into account. Instead, the apparel is modeled as a collection of cables and hyperbolic cosine curves, Weil added the stiffness
factor as a distance constraint\cite{Weil1986}. As the physical properties of clothes are omitted or not accurate, geometric models do not work well with dynamic models as well as they do with 
stationary renders\cite{Weil1986}.

\subsubsection{Physical Garment Modeling}
Physical approaches model the cloth as systems of springs-masses or particles, or as a continuous flexible material to be solved as a elasticity problem.

The spring-mass system is first presented by Haumann and Parent\cite{Haumann1988}, which converts 
each vertex into a point mass and converts each edge into a spring. The simulation is attained by solving the spring-mass equations. Further improvements on spring-mass systems include
different sets of springs for orthogonal axes and distance constraints to achieve more garment-like simulations\cite{Provot1996}. The NVIDIA PhysX system utilizes an enhanced 
spring-mass system for its simulations\cite{Kim2011}.

Terzopoulos et al.\cite{Terzopoulos1987} presented elastically deformable models based on continuum mechanics and differential geometry. Another continuum based approach which 
sacrifices accuracy for performance by focusing on numerical solutions was described by Baraff and Witkin\cite{Baraff1998}. Elasticity solutions rely on energy interactions between 
the particles and achieve a solution by minimizing the total energy stored within the whole mesh.

\section{Virtual Fitting Rooms}
\label{section_related_virtual_fitting}

Virtual fitting rooms have been a research subject for more than a decade. Protopsaltou~et~al.~\cite{Protopsaltou2002} developed an Inter\-net-based approach 
for virtual fitting rooms, although it was not real time and required marker-based motion capture systems for animation. Zhang~et~al.~\cite{Zhang2008} used a 
multi-camera system utilizing shell fitting space (SFS)~\cite{Cheung2005} techniques to build a real time intelligent fitting room.

Advances in time-of-flight technology made depth sensors available at consumer-level prices with better performance. This prompted a wave of research 
based on depth sensors in various fields, such as rehabilitation~\cite{Chang2011}, indoor modeling~\cite{Henry2012}, and medicine~\cite{Gallo2011}. Another 
topic that attracted significant attention from both researchers and companies is real-time virtual fitting rooms~\cite{Meng2010}. Giovanni~et~al.~\cite{Giovanni2012} 
developed a virtual try-on system utilizing a calibrated set of Kinect and high definition cameras, while comparing the two state-of-the-art depth sensing software 
development kits (SDKs)-OpenNI~\cite{OpenNI2102} and Kinect for Windows~SDK~\cite{Microsoft2013}. While most frameworks utilize garment meshes with physics 
simulation~\cite{Fitnect2012,Styku2013}, another intriguing approach is using a pre-recorded apparel image database, from which the images are superpositioned onto the
RGB video of the user~\cite{Hauswiesner2013,Zhou2012}.  

One problem with depth sensors is the feeble quality and noisiness of the depth stream. This problem is analyzed in depth by Khoshelham~and~Elberink~\cite{Khoshelham2012}
 and concluded that the standard deviation reaches two centimeters in a measuring distance of three meters. Matyunin~et~al.~\cite{Matyunin2011} attempted to improve the 
 quality by filtering with additional information from the attached RGB camera.  

A key purpose of both virtual and real fitting rooms is giving the customer the look and feel of a cloth with a specific size on the user's body, so the user can choose
the appropriate size for him. Embedding the feature of matching cloth sizes with users requires capturing the users' body dimensions. More advanced frameworks even construct
virtual avatars with input from only one depth sensor~\cite{Cui2013,Cui2010}. On the other hand, despite these works provide higher detail avatars and keener measurements,
which might be more suitable for made-to-measure type of framework, the process requires too much time to work with a real-time `fixed-size try-on' virtual fitting room application
where simple body height and width measurements are sufficient. These applications require a faster approach along with a specialized garment design framework such as the works of 
Yasseen~et~al.~\cite{Yasseen2013} or Meng~et~al.~\cite{Meng2010}. There are also notable studies for made-to-measure technologies for online clothing stores~\cite{Cordier2003},
shape control techniques for automatic resizing of apparel products~\cite{Meng2012}, modeling a 3D garment on a 3D human model by 2D sketches~\cite{Wang2003}, and garment pattern
design using 3D body scan data~\cite{Kim2003}. A recent study~\cite{Kim2013} shows that such applications are well-received by public and have potential commercial uses.     


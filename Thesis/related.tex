\chapter{Related Work}
\label{chapter_related_work}

Virtual fitting frameworks are complex systems composed of many modules. The related works on the major components of our framework are summarized in this chapter, 
along with the history of the general framework. 

The overall framework can be divided into four major modules: \textit{human body modeling and animation} , \textit{motion capture systems} and 
\textit{physics engines, cloth modeling and simulation and collision detection}. Although these topics are connected in many ways, their foundations are distinct 
and should be discussed seperately, followed by the discussion of the work on virtual fitting rooms.

\section{Human Body Modeling And Animation}
\label{section_related_modeling}

Although the human and apparel modeling both have foundations in 3D mesh creation, they require different traits and qualities. Human body modeling utilizes disciplines such as rigging and 
skinning, whereas apparel modeling is mostly based on physics simulations.

\subsection{Human Body Modeling}
As we humans are mostly the main characters in virtual worlds, very different methods and techniques exist for human body models and animations. Determining the suitable one 
starts with the requirements of the application. Real-time applications require a certain level of simplicity, as the simulation time cannot exceed the frame duration. Offline 
applications can utilize very higher detail models, looking much more realistic. The basis for both extremes however, are the same, which is a skeleton. The approach is starting 
with a connected set of rigid objects named as \textit{bones}, continuing by adding layers of muscle, skin, hair and others, depending on the required quality level. Called \textit{layered
modeling technique}, this is a very common modeling technique used in computer graphics \cite{Chadwick1989}. The animation is achieved by rotating the bones, which are followed by 
upper layers. This technique also improves the reusability of the framework, as the same animation sequence can be used for multiple body models with different detail levels utilizing the 
same base skeleton.   

The articulated skeleton consists of a hierarchical structure of joints and limbs to model a human-like skeleton. Joints are the points which act as the origin of the respective 
local coordinate space. The limbs are the rigid segments which connect the joints in the hierarchy. Rotation in the local coordinate systems defined by the joints cause the rigid
limbs to be rotated, resulting in the motion. The complexity of the model can be determined by the number of joints and the degrees of freedoms - abbreviated as \textit{DOF}s.
Degree of freedom is defined as ``the number of independent parameters that define its configuration''\cite{Lazard2013}. A joint can rotate and translate in at most three orthagonal
directions, hence the maximum DOF a joint can have is six. Although having the maximum number of DOFs in a human body model might seem like a good way to improve the realism, 
however this also increases the complexity of the structure, resulting in more mathematical operations. As most human-body joints can only rotate, not translate, assigning six 
degrees of freedom to every joint is redundant. Furthermore, angular and axis constraints with certain joints (such as knee or elbow) further simplify the model while making it 
more realistic. 

In order to provide a common basis and a standard for modeling of 3D humans with hierarchical skeletons, Humanoid Animation (H-Anim) specification was developed by 
Web3D Consortium\cite{HANIM}. Different levels of articulation are provided in X3D/VRML format, focusing specifically on humanoid objects rather than random 
articulated figures. H-Anim standard provides a common ground for applications to be classified depending on their humanoid animation complexity, mainly by the 
number of joints and DOFs. 

\subsection{Human Body Animation}
\label{section_related_human_body_animation}

Animating humanoid meshes is a complex and old subject of computer science, as there are many factors which contribute to the way humans move. The task gets 
even harder with the ability of the human eye to distinguish very minor unnatural movements. The long history of humanoid animation starts with stick figures 
and evolves to multi-layered high resolution meshes. 

Stick figured animation dates back to 1970s, where the technology would limit the qualities of animation to one dimensional limbs\cite{Badler1979}.
With the advances in computer hardware, the details have improved and the complexities are increased. Surface models were the first improvement on top 
of the original stick figure animation. A surface or ``skin'', which envelopes the articulated skeleton is 
introduced to the model. The translation of the surface varies depending on how the vertices are assigned to the bones. The process of assigning vertices to 
a specific joint or set of joints is called skinning. The quality of the animation depends on both the complexity of the skeleton as well as the skinning 
quality and technique. 

The initial approach to the animation of enveloped surface was assigning weights to the individual polygons. However, this approach resulted in broken surfaces
almost every frame. The first solution to this problem was introduced by Komatsu \cite{Komatsu1988}, where a continuous deformation function is used with respect 
to the joints. 

The next step in skinning was assigning vertices to joints instead of polygons\cite{Lander1988}. This simple difference allowed a polygon to be assigned to multiple bones, 
preventing two polygons from seperating as the common vertices would not get ripped.

Although assigning vertices instead of polygons to bones improved the realism significantly, it produced artifacts in extreme rotations. Inspired by the true 
nature of human skin and deformation, the new solution introduced assigning a vertex to multiple joints. Called linear blend skinning, this technique further 
improved the quality of character animations. However, it still was not sufficient with certain parts of body such as forearm and elbow, where the bone 
positioning and configuration are more complex than a single series of connected bones. An example of this situation can be seen in Figure \ref{fig:forearm-comparison}.
A single bone cannot imitate the twisting motion enabled by two parallel bones. Various solutions to this problem has been proposed, ours is described in 
Section \ref{subsection_bone_splitting}. 

A new deformation technique called Double Quaternion Skinning overcomes these artifacts without introducing additional time complexity\cite{Kavan2007}, even 
improving the performance. Quaternions, which are primarily used as a notation for rotations can also be used to define translations. Dual Quaternions can 
be blended for rigid transformations and produce much more realistic results.

Another approach to fixing the extreme rotation situations was proposed by Kavan et al.\cite{Kavan2009}, where the bones which could not produce realistic 
results would be split into subbones in runtime. This approach, althouhg successfully correcting the otherwise present artifacts, required significantly more
computational power and was not suitable for real-time applications. 


\section{Motion Capture Systems}
\label{section_related_mocap}
 Since the human body is a complex articulated system, creating artificial motions from scratch is found to be tedious, labor intensive and not very successful.
 The solution to providing animation data to virtual models is recording the motions of real humans and applying the same transformations. First bricks laid by
 Calvert et al. \cite{Calvert1982}, motion capture systems today utilize a variety of techniques to capture the human and other motions for different purposes.
 
 There are two base disciplines for motion capture systems- optical and non-optical.
 
\subsection{Non-Optical Motion Capture Systems}
 
 Non-optical systems are based on mechanics, inertia\cite{Miller2004} and magnetics\cite{Yabukami2000}. Mechanical systems were the earliest examples of motion capture systems and 
 their cumbersome hardware requirements make them hard to use. Inertial systems utilize inertia sensors to determine the global orientation of the body part they 
 are attached to, which can later be converted to local orientations in post processing. Magnetic systems perform the same operation, except they do so by measuring 
 the magnetic field emitted by the magnetic markers. Non-optical systems tend to deliver more accurate results than optical motion capture systems, although 
 their hardware requirements and harness to use are two major drawbacks. 
 
\subsection{Optical Motion Capture Systems}

 Optical systems are based on recording the target in action by one or more 
 cameras. The most common approaches in optical motion capture systems utilize some sort of markers placed on key positions of the target. Markers can be passive
 \cite{Sementille2004} or active\cite{Maletsky2007}, depending on whether they just reflect the light or they emit light themselves. Regardless, their task is 
 identical in both cases, providing the camera with the positional information of key parts of the body. 
 
 With the advances in computer processing power and camera technology, markerless motion capture systems have emerged\cite{Cheung2003}. Theobalt, Aguiar and their team in Max 
 Planck Institute have played an important role in the markerless human motion capture systems from multi view video sequences \cite{Aguiar2007,Gall2009,Liu2011}. Their framework
 utilizes 8 or more cameras placed on a circle around the target. They construct a volumetric visual hull by getting the intersection of extruded 2D silhouettes 
 - which is called shape from silhouette technique\cite{Cheung2000,Cheung2005}. Using a set of cameras rather than a single camera is a remedy to the self-occlusion
 problem. After the visuall hull of the user is acquired, the hull is segmented into body parts by fitting a pre-defined body model. Accurate as they are, these
 applications require immense computing power and are not suitable for real time applications. 
 
 The emergence of the consumer-level depth sensors at affordable costs opened a new page for markerless motion capturing\cite{Dutta2012}. As the depth sensors operate in real time
 and the visual hull is the input rather than a processing product, the computation time for skeletal position estimation is considerably lower, enabling 
 real-time motion transferring from actors to virtual avatars. However, depth sensors suffer from the same disadvantage as single-camera systems- self occlusion,
 although this problem can be solved partially by utilizing mutliple depth sensors\cite{Berger2011}.
 Furthermore, the IR and TOF depth sensing technology are not evolved enough yet to provide high resolution depth frames and produce quite a bit of noise, hence 
 reducing the output motion quality. Various filters for improving the results have been developed and applied\cite{Matyunin2011,Camplani2012}. 
 
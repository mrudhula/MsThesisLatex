\chapter{User Tracking}
\label{appendix_user_tracking}

\section{Hardware}

User tracking has always been both a challenge and a valued feature in image processing. Until the availability of time-of-flight cameras, user tracking was dependent on RGB cameras. Although RGB cameras are sufficient for user tracking, they are proven to be harder to use for body articulation and joint estimation, mostly because of the complexity of human body, self occlusions, and the difficulties of body segmentation based on pixel colors alone. Researchers started with still images, than experimented with image sequences from multiple cameras. Most common technique, called {\em Shape From Silhouette (SFS)}, extracts the body silhouette from the image and constructs a body shape with silhouettes from multiple calibrated cameras~\cite{Cheung2005}. SFS algorithms evolved from spatial to temporal tracking and their accuracy improved even more~\cite{Cheung2005}. 

However, RGB based accurate user articulation techniques required many cameras-a financial problem. After the need for extensive imaging hardware, the processes required to calibrate the cameras initially, extract and combine the silhouettes, build a shape and articulate the result. These processes require very complex algorithms, many man-hours to implement and very powerful computing infrastructure. Instead of RGB imaging, we searched for an alternate type of device which can capture the depth of the field. Although there are a variety of such devices, from sonars to Laser Scanners, the one most appropriate for user tracking is time-of-flight cameras. They have significant advantages over stereo vision and laser tracking, such as simplicity, speed (up to 100 frames per second), and accuracy in distance~\cite{Kourosh2012}.

Choosing the most accurate time-of-flight camera is easy, as Microsoft Kinect is not only the cheapest and the most available of them all, it is also the most powerful and had an extensive developer community. We utilized the Kinect for XBOX rather than Kinect for Windows in this study because of its distance and performance characteristics.

\section{Software}

The user tracking process with Kinect is much simpler compared to SFS techniques, due to the shape being available mostly with the depth field output. However, proper articulation still required lots of different algorithms and time. In order to speed up the user tracking and articulation, we utilized the Kinect for Windows SDK framework. KFW provides the framework for capturing and utilizing the various types of streams from Natural Interaction devices, also provides abstract modules for accessing complex functionalities, such as skeletal tracking~\cite{OpenNI2102}. 

With the integration of these modules to the simulation software, we are able to acquire the joint positions and orientations from the depth sensor with almost no effort except the integration itself. With the current hardware/software configuration, we acquire 20 joint positions and orientations at 30 frames per second, enough to reproduce the movement of the user on the virtual model. Other than the joint information, we also acquire the depth and image streams from the depth camera for user body measurement purposes. We also use the image stream to present the obtained results, comparing the user movement with the simulated environment.
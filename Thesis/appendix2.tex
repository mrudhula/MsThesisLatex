\chapter{User Tracking}
\label{chapter2}

\section{Hardware}

User tracking has always been both a challenge and a valued feature in Image Processing. Until the availability of Time-Of-Flight cameras, user tracking was dependent on RGB cameras. Although RGB cameras are sufficient for user tracking, they are proven to be harder to use for body articulation and joint estimation, mostly because of the complexity of human body, self occlusions and the difficulties of body segmentation based on pixel colors alone. Researchers started with still images, than experimented with image sequences from multiple cameras. Most common technique was to extract the body silhouette from the image and construct a body shape with silhouettes from multiple calibrated cameras- Shape From Sihouette (SFS) \cite{Cheung2005}. SFS algorithms evolved from spatial to temporal tracking and their accuracy improved even more \cite{Cheung2005}. 

However, RGB based accurate user articulation techniques required many cameras-a financial problem. After the need for extensive imaging hardware, the processes required to calibrate the cameras initially, extract and combine the silhouettes, build a shape and articulate the result. These processes require very complex algorithms, many man-hours to implement and very powerful computing infrastructure. All these requirements made shape-from-silhouette algorithms hard to utilize for me.

Instead of RGB imaging, I searched for an alternate type of device which can capture the depth of the field in front of it. Although there are a variety of such devices, from sonars to Laser Scanners, the one most appropriate for user tracking was Time-Of-Flight cameras. They have significant advantages over Stereo-Vision and Laser Tracking in simplicity, are fast (up to 100 fps) and accurate in distance \cite{Kourosh2012}.

Choosing the most accurate Time-Of-Flight camera was easy, as Microsoft Kinect was not only the cheapest and the most available of them all, it was also the most powerful and had an extensive developer community. I utilized the Kinect for XBOX rather than Kinect for Windows in this study, due to its distance and performance characteristics.

\section{Software}

The user tracking process with Kinect was much simpler compared to SFS techniques, due to the Shape being available mostly with the depth field output. However, proper articulation still required lots of different algorithms and time.

In order to speed up the user tracking and articulation, I utilized the OpenNI framework along with PrimeSense NITE package and SensorKinect drivers. OpenNI provides the framework for capturing and utilizing the various types of streams from Natural Interaction devices, also provides abstract modules for accessing complex functionalities, such as skeletal tracking \cite{OpenNI2102}. PrimeSense NITE package is a software that bundles with OpenNI, and provides skeletal tracking, hand tracking and other functionalities which can be accessed via OpenNI framework \cite{PS2102}. 

With the integration of these modules to my application, I was able to acquire the joint positions and orientations from the depth sensor with almost no effort except the integration itself. With the current hardware/software configuration, I acquire 15 joint positions and orientations at 30 fps, which is enough to reproduce the movement of the user on the virtual model. Other than the joint information, I also acquire the depth and image streams from the depth camera. I will be using the image stream to present the results I have obtained, comparing the user movement with the simulated environment.

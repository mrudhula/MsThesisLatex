\chapter{Hand Tracking}
\label{appendix_hand_tracking}

\section{OpenCV}
 
Although OpenNI/NITE provide the joint information, useful functions for a smooth user interface, such as hand state recognition or hand swipe filters are omitted in the open source natural interaction libraries that we use. In order to simulate mouse-clicking behavior, we track the hands of the user to be used as cursors, notice open/close hand gestures for clicking events. In order to implement the algorithms for the proposed hand-track solution, we selected to work with OpenCV, due to its maturity, community and integration with other libraries. OpenCV not only provides basic functions to perform complex and processor-intensive image processing functions such as, facial recognition system, gesture recognition, stereoscopic 3D and segmentation, it also has a very vast machine learning aspect, including boosting, decision three learning and many more features~\cite{opencv_library}.

\section{The Process}

Utilizing such a powerful middleware as a depth sensor, we are able to perform very robust background subtraction with almost no effort. Skeletal body tracking is another embedded property of the software that we use, giving a speed boost. We implemented two different techniques: \em{hand state recognition} and \em{hand swipe recognition}. Hand swipe recognition is simpler compared to hand state recognition. It is just a matter of keeping track of the 3D position of the hand, and keeping a listener that is activated when the 3D velocity of the hand exceeds a certain threshold. We also perform a number of optimizations on this function to make it invariant with the size and location of the user. Open/close hand recognition is harder than hand swipe recognition. We perform advanced image processing in order to determine the state of the hand successfully at relatively low resolutions and large distances. The algorithm is shown in Figure \ref{fig:hand_recognition_cycle}:

\begin{figure}[h]
\centerline{\fbox{\psfig{figure=figures/hand_recognition_cycle.eps,width=1.0\textwidth}}}
\caption{Hand recognition algorithm}
\label{fig:hand_recognition_cycle}
\end{figure} 

\begin{enumerate}
\item The size information for the region of interest is drawn from the distance between the users head and users neck.
\item The hand is located using skeletal body tracking.
\item The marked region is copied from the depth stream 
\item Two dilation and one erosion operations are performed to smooth the hand image
\item The contour is found on the filtered image
\item The convex hull of the found contour is calculated.
\item The depth difference between the hull and the actual contour is taken as the reference for hand-state.
\end{enumerate}

Figure \ref{fig:open_closed_hands} depicts the results of experiments. The left part of the figure shows the hand in open state, whereas the hand is closed on the right part.

\begin{figure}[h]
\centerline{\psfig{figure=figures/open_closed_hands.eps,width=1.0\textwidth}}
\caption{Hand images and contours from depth stream}
\label{fig:open_closed_hands}
\end{figure}


%Ultimately, I plan to implement the algorithm described in~\cite{Tang2011}, where the author claims to have achieved 96\% correct 
%results. I have not included RGB image in the process yet, neither have I implemented complex machine learning. In addition to these 
%methods, I will record hand images for testing objectively. These topics are in my future research plans. 
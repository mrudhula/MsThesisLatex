\chapter{Introduction}
\label{chapter_introduction}

Computer graphics are being used in more and more areas today to help with visualization of data, such as in big data and crowd simulation. Human body animation and cloth simulation have been two significant subjects of the field for a while. Although there are cases where the simulation results are incredibly life-like, the task is still nothing trivial. 

One of the most time-consuming stages of apparel shopping is the customer trying the apparels by putting them on, which is not even possible in online stores. With the advances in augmented reality technologies, virtual fitting rooms are slowly taking their places in both real and virtual stores~\cite{Fitnect2012,Styku2013} to improve the quality of apparel trial experience while also making it faster. These frameworks utilize both humanoid and cloth animation features, hence they are limited by the bottlenecks in both fields. The demand for virtual dressing frameworks is increasing with the spread of online apparel commerce and the interactive advertisement platforms. There are various features of virtual fitting frameworks, where each has different priorities in different types of applications:

\begin{itemize}
  \item The apparel can be displayed on a virtual avatar or on real photos or videos of the user. The former is used more in design stages, the latter more in online and in-store try-on frameworks. Avatars can be static or dynamic, animated with the motions of the user or with pre-recorded animations. 
  \item A virtual fitting room framework can utilize an apparel image database which consists of pre-recorded two dimensional photos of apparels in various poses to render the apparel, or it can utilize a virtual three dimensional model. Former approach is considered to require more preprocessing and cause lapses between poses, however the rendered apparel looks realistic as it is a two dimensional photo. Latter approach enables rapid three dimensional apparel model generation and more realistic material and physical simulations.
  \item If the three dimensional approach is used, the apparel mesh can be processed with physical simulation or can be stagnant. The former requires more advanced frameworks and more powerful hardware, making them more suitable for desktop applications rather than online fitting rooms. 
  \item A virtual fitting room framework can scale the apparel and meshes according to the active user. The scaling can be standardized where a fixed size among possible size options would be offered to the customer, or it can be detailed scaling similar to made-to-measure tailoring. The latter approach is more complex compared to the former, because a larger set of measurements are needed with higher precision.
\end{itemize}

On the low-end of the virtual fitting room spectrum, there are super positioned 2D images of the user and the apparel without any animation. Advanced virtual fitting rooms, on the other hand, show the apparel items either on the video of the user or on a virtual avatar, both scaled to reflect the user's body characteristics~\cite{FaceCake2013}. Physics-based garment simulation for a better fitting experience is included in the high end frameworks~\cite{Styku2013}. Our approach utilizes a three dimensional virtual avatar which is updated with user motions captured through a depth sensor. The apparels are rendered as three dimensional models and updated with physical simulation.  

\section{Our Approach}

This study is aimed to develop a novel virtual fitting room framework that provides all the basic features expected from such an application, along with enhancements in various aspects for higher realism. These enhancements include motion filtering, customized user scaling, and physics engine. Motion filtering process starts with temporal averaging of joint positions in order to overcome the high noise of the depth sensor. However, temporal averaging does not prove to be sufficient because unnatural movements take place due to limited recognition capabilities and self-occlusion. Customized joint angle filters, along with bone splitting to let limbs twist in a more natural way and footskate correction filters are implemented.

The avatar utilizes a skeleton that conforms with the LOA 2 of H-ANIM 200x specification~\cite{HANIM}, although not all bones are used for animation because of the data received from the depth sensor. The skeleton and mesh are modeled in Blender~\cite{Blender}, exported and used in binary format. The simulated apparel pieces are also modeled in Blender, although they are exported in Wavefront OBJ format in order to be parsed by the physics engine. They are binarized on-the-run to be used by the game engine. 

The cloth pieces to be fitted on the user's avatar must first be scaled accordingly. To this end, a body measurement process is implemented, which starts with depth map smoothing, in order to reduce the noise. Afterwards, the filtered depth map is utilize along with filtered user joints to measure a set of parameters, which are used in conjunction to estimate the body height and width. These parameters are averaged over time to minimize the error.

The physics engine utilizes collision spheres and capsules to perform collision detection. The correct sphere radii and positions are determined during body measurements. The virtual avatar is aligned with a set of invisible spheres and capsules are aligned with joints and limbs, which are updated in real time and used in collision detection. Cloth particles are also affected by gravity and inertia.

\begin{figure}[h]
\centerline{\psfig{figure=figures/overall.eps,width=1.00\textwidth}}
\caption{The overall virtual dressing framework}
\label{fig:overall}
\end{figure}

\section{System Architecture}

The framework operates in two distinct stages: {\em modeling} and {\em simulation}. The modeling stage consists of preparing the avatar and cloth meshes for the simulation. The base low-detail avatar meshes, a male and a female, are acquired from online sources~\cite{Mmava2012,Gomer2013}, rigged with a skeleton, and painted with materials and textures. The base apparel meshes are also acquired from online sources~\cite{LadyJewell2012,3dregenerator2013,Axel2013,Borodin2013,PS3D2013,Alperin2013}. They are aligned with the avatar meshes, painted, and their physical properties are specified. After the models are ready for simulation, they are exported in appropriate file formats to be loaded by the simulation stage. 

The simulation stage starts after a user is identified. It is initialized by performing user body measurements and scaling the avatar and apparel meshes accordingly. The render cycle starts with fetching the user skeletal joint information from the depth sensor. The virtual avatar and the static apparel meshes are updated by applying the acquired joint orientations. The collision spheres that coincide with the skeleton joints are also updated during this process. The dynamic apparel meshes are updated with new positions and orientations and the collision data and the updated topology information are transferred from the physics environment to the virtual environment, followed by rendering. The overall virtual dressing framework is shown in Figure~\ref{fig:overall}.  


\section{Organization of the Thesis}

The thesis is organized as follows. Chapter~\ref{chapter_related_work}, we give related work on virtual fitting rooms and depth sensors. Chapter~\ref{chapter_3d_model} describes the human and cloth modeling for virtual fitting room. Chapter~\ref{chapter_animation} focuses on the animation techniques along with various optimizations for a realistic experience. Chapter~\ref{chapter_cloth_simulation} discusses the physics engine and cloth simulation process. Chapter~\ref{chapter_cloth_resizing} deals with the cloth resizing process for a customized fitting experience. The experiments, performance qualities and results are presented in~\ref{chapter_experiments}. Chapter~\ref{chapter_conclusion} outlines the thesis and shows the future direction of this research. Appendix~\ref{appendix_ogre_framework} describes the game engine that provides the boilerplate functions for our framework. Appendix~\ref{appendix_user_tracking} gives information about the depth sensor and its user tracking capabilities. A user interaction feature, depth-based hand tracking is explained in Appendix~\ref{appendix_hand_tracking}.
